
global DATAopts;
DATAopts = UCFInit;

% Parameter settings for descriptor extraction
clear descParam
descParam.Func = @FEVid_deepFeatures;
descParam.MediaType = 'DeepF';
descParam.Layer='pool5';
descParam.net='tempVGG16';
descParam.Normalisation='ROOTSIFT';

descParam.numClusters = 256;

descParam.pcaDim = 256;

descParam

%%%%%%%%%%
bazePathFeatures='/home/ionut/Data/action_temporal_vgg_16_split1_features_opticalFlow_tvL1_UCF50/Videos/'; %change


vocabularyIms = GetVideosPlusLabels('smallEnd');

vocabularyImsPaths=cell(size(vocabularyIms));

for i=1:length(vocabularyImsPaths)
    vocabularyImsPaths{i}=[bazePathFeatures char(vocabularyIms(i)) '/pool5.txt'];
end


vocabs=cell(1, 2);
pcaMaps=cell(1, 2);


parpool(2);
parfor i=1:2
    if i==1                                            
        [vocabs{i}, pcaMaps{i}] = CreateVocabularyKmeansPca(vocabularyImsPaths, descParam, ...
                                                        descParam.numClusters, descParam.pcaDim);
    else
        [vocabs{i}, pcaMaps{i}] = CreateVocabularyGMMPca(vocabularyImsPaths, descParam, ...
                                                        descParam.numClusters, descParam.pcaDim);
    end

end
delete(gcp('nocreate'))

pcaMap=pcaMaps{1};
vocabulary=vocabs{1};
gmmModelName=vocabs{2};




%vocabulary = NormalizeRowsUnit(vocabulary); %make unit length

% Now create set
[vids, labs, groups] = GetVideosPlusLabels('Full');
pathFeatures=cell(size(vids));

for i=1:length(pathFeatures)
    pathFeatures{i}=[bazePathFeatures char(vids(i)) '/pool5.txt'];
end



    [tDesc] = MediaName2Descriptor(pathFeatures{1}, descParam, pcaMap);
    %tDesc=NormalizeRowsUnit(tDesc);
    tVLAD=VLAD_1_mean(tDesc, vocabulary);

vladNoMean=zeros(length(vids), length(tVLAD), 'like', tVLAD);    
vlad=zeros(length(vids), length(tVLAD), 'like', tVLAD);
vlad1=zeros(length(vids), length(tVLAD), 'like', tVLAD);
avgEncode=zeros(length(vids), length(tVLAD), 'like', tVLAD);
maxEncode=zeros(length(vids), length(tVLAD), 'like', tVLAD);

[tDesc] = MediaName2Descriptor(pathFeatures{1}, descParam, pcaMaps{2});
FV=mexFisherAssign(tDesc', vocabs{2})';

fisherVectors=zeros(length(vids), length(FV), 'like', FV);

parpool(24);

% Now object visual word frequency histograms
fprintf('Descriptor extraction  for %d vids: ', length(pathFeatures));
parfor i=1:length(pathFeatures)
    fprintf('%d \n', i)
    % Extract descriptors
    
    [desc, info, descParamUsed] = MediaName2Descriptor(pathFeatures{i}, descParam, pcaMaps{1});
   % desc = NormalizeRowsUnit(desc);
   
    
    vladNoMean(i, :)=VLAD_1(desc, vocabulary{1});


    vlad1(i, :)=VLAD_1_mean(desc, vocabulary);
    vlad2(i, :)=comb_percentage_minVocab_VLAD_1(desc, vocabulary, 1/2)

    
        
         if i == 1
             descParamUsed
         end
         
end
fprintf('\nDone!\n');




%% Do classification

nEncoding=2;
allDist=cell(1, nEncoding);

n_vlad1=NormalizeRowsUnit(PowerNormalization(vlad1, 0.5));
allDist{1}=n_vlad1 * n_vlad1';
clear n_vlad1

n_vlad2=NormalizeRowsUnit(PowerNormalization(vlad2, 0.5));
allDist{2}=n_vlad2 * n_vlad2';
clear n_vlad2


all_clfsOut=cell(1,nEncoding);
all_accuracy=cell(1,nEncoding);

cRange = 100;
nReps = 1;
nFolds = 3;


for k=1:nEncoding

% 
% Leave-one-group-out cross-validation
parfor i=1:max(groups)
    testI = groups == i;
    trainI = ~testI;
    trainDist = allDist{k}(trainI, trainI);
    testDist = allDist{k}(testI, trainI);
    trainLabs = labs(trainI,:);
    testLabs = labs(testI, :);
    
    [~, clfsOut{i}] = SvmPKOpt(trainDist, testDist, trainLabs, testLabs, cRange, nReps, nFolds);
    accuracy{i} = ClassificationAccuracy(clfsOut{i}, testLabs);
    fprintf('%d: accuracy: %.3f\n', i, mean(accuracy{i}));
end

all_clfsOut{k}=clfsOut;
all_accuracy{k}=accuracy;

k
perGroupAccuracy = mean(cat(2, accuracy{:}))'

end

delete(gcp('nocreate'))




mean(mean(cat(2, all_accuracy{1}{:})))
mean(mean(cat(2, all_accuracy{2}{:})))


